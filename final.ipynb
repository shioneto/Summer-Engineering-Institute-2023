{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "945d0fce-4d0a-4a9f-b0fb-0a2c7fd52a45",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "1.) Color Change Detection in video, use same frame as rest of video. (Needs to be done on seperate instance of picture/frame as detections as bounding box may cause issues with color.\n",
    "2.) Use premade model for the moment to genereate bounding boxes in frames\n",
    "3.) Set lines in model to \n",
    "3.) Use bounding box boundaries to determine crossings against "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15c975b6-8c6b-401c-9b9a-8b2189ca0296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "# import supervision as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5599589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_x, car_y, car_x2, car_y2, Matchpersent, indexModule = -1, -1, -1, -1, -1, -1\n",
    "def display_roi(row_data):\n",
    "    global car_x, car_y, car_x2, car_y2, Matchpersent, indexModule\n",
    "    car_x, car_y, car_x2, car_y2, Matchpersent, indexModule = int(row_data[0]), int(row_data[1]), int(row_data[2]), int(row_data[3]), int(row_data[4] * 100), int(row_data[5])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b0d49b-50ac-41f1-a7cb-dbc4b92e9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_x, roi_y, roi_width, roi_height = -1, -1, -1, -1\n",
    "selecting_roi = False\n",
    "\n",
    "def select_roi(event, x, y, flags, param):\n",
    "    global roi_x, roi_y, roi_width, roi_height, selecting_roi\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        roi_x, roi_y = x, y\n",
    "        selecting_roi = True\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        roi_width, roi_height = x - roi_x, y - roi_y\n",
    "        selecting_roi = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aec67e1-1966-472f-998f-4d2721bca079",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "roi_x1, roi_y1, roi_width1, roi_height1 = -1, -1, -1, -1\n",
    "\n",
    "def select_roi1(event, x, y, flags, param):\n",
    "    global roi_x1, roi_y1, roi_width1, roi_height1, selecting_roi\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        roi_x1, roi_y1 = x, y\n",
    "        selecting_roi = True\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        roi_width1, roi_height1 = x - roi_x1, y - roi_y1\n",
    "        selecting_roi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "187892b2-c804-476b-a577-ba03ea01fba7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "roi_x2, roi_y2, roi_width2, roi_height2 = -1, -1, -1, -1\n",
    "\n",
    "def select_roi2(event, x, y, flags, param):\n",
    "    global roi_x2, roi_y2, roi_width2, roi_height2, selecting_roi\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        roi_x2, roi_y2 = x, y\n",
    "        selecting_roi = True\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        roi_width2, roi_height2 = x - roi_x2, y - roi_y2\n",
    "        selecting_roi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eda33f6e-1bb6-4f0e-a2f4-eae1ff870440",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "roi_x3, roi_y3, roi_width3, roi_height3 = -1, -1, -1, -1\n",
    "\n",
    "def select_roi3(event, x, y, flags, param):\n",
    "    global roi_x3, roi_y3, roi_width3, roi_height3, selecting_roi\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        roi_x3, roi_y3 = x, y\n",
    "        selecting_roi = True\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        roi_width3, roi_height3 = x - roi_x3, y - roi_y3\n",
    "        selecting_roi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5acb4aa8-2187-4977-ad87-8274842e0323",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "line_x, line_y, line_x1, line_y1 = -1, -1, -1, -1\n",
    "drawing = False\n",
    "\n",
    "def select_line(event, x, y, flags, param):\n",
    "    global line_x, line_y, line_x1, line_y1, drawing\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        line_x, line_y = x, y\n",
    "        drawing = True\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        line_x1, line_y1 = x, y\n",
    "        drawing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2fd5300-45d5-4b9d-a4bb-d931efd286d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def color_grab(frame, roi_y, roi_x, roi_width, roi_height):\n",
    "    roi = frame[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width]\n",
    "\n",
    "    # Convert the ROI to the desired color space (e.g., RGB or HSV)\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Compute the mean color of the ROI\n",
    "    mean_color = np.mean(roi, axis=(0, 1))\n",
    "        \n",
    "    return mean_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96d2c97e-cb49-494f-8fbb-0c73d0e9b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overlap(box_coordinate,line_start, line_end):\n",
    "    #calcukate the slope\n",
    "    global testing\n",
    "    testing = box_coordinate\n",
    "    m = (line_end[1] - line_start[1])/(line_end[0]-line_start[0])\n",
    "    b = (line_start[1] - m*line_start[0])\n",
    "    x2 = box_coordinate[:,0]\n",
    "    y2 = box_coordinate[:,1]  \n",
    "    x1 = box_coordinate[:,2]\n",
    "    y1 = box_coordinate[:,3]    \n",
    "    \n",
    "    overlap  = False \n",
    "    results = []\n",
    "    i = 0\n",
    "    while i < len(box_coordinate):\n",
    "        if (line_start[0] < x1[i] or line_start[0] < x2[i]):\n",
    "            if (line_end[0] > x1[i] or line_end[0] > x2[i]):\n",
    "                if m*x1[i]+b < y1[i] and m*x2[i]+b > y1[i]:\n",
    "                    overlap = True\n",
    "                elif m*x1[i]+b > y1[i]and m*x2[i]+b < y1[i]:\n",
    "                    overlap = True\n",
    "                else:\n",
    "                    overlap = False\n",
    "            else:\n",
    "                overlap = False\n",
    "        else:\n",
    "            overlap = False\n",
    "\n",
    "        i+=1\n",
    "        results.append(overlap)\n",
    "    results = np.array(results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8b46a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delay in miliseconds/Setup video\n",
    "frame_delay = 145000\n",
    "frame_width = 1100\n",
    "frame_height = 700\n",
    "\n",
    "#RGB color to be compared to to check for a shift, assuming signals default is black, in which case 0,0,0 was used\n",
    "reference_color = (0, 0, 0)  # Black\n",
    "\n",
    "threshold = 100\n",
    "\n",
    "#Pixels for window to open from top left of window\n",
    "opening_x = 10\n",
    "opening_y = 10\n",
    "video_dir = r\"C:\\Users\\brema\\Desktop\\GX020001.MP4\"\n",
    "\n",
    "   \n",
    "size = (frame_width, frame_height)\n",
    "\n",
    "#Opens video and starts from desired time after start\n",
    "video_capture = cv2.VideoCapture(video_dir)\n",
    "video_capture.set(cv2.CAP_PROP_POS_MSEC, frame_delay)\n",
    "resultVid = cv2.VideoWriter(r'C:\\Users\\magic\\Desktop\\test.avi', cv2.VideoWriter_fourcc(*'MJPG'), 10, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f20cd9a6-42c2-4a22-831b-61701120a32a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Opens frame at chosen start to draw the ROI of the top left signal\n",
    "ret, frame = video_capture.read()\n",
    "cv2.namedWindow('Select ROI - Top Left Signal')\n",
    "cv2.setMouseCallback('Select ROI - Top Left Signal', select_roi)\n",
    "frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('Select ROI - Top Left Signal', frame)\n",
    "    cv2.moveWindow('Select ROI - Top Left Signal', opening_x, opening_y)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('q') or not ret:\n",
    "        break\n",
    "\n",
    "    if not selecting_roi and roi_width > 0 and roi_height > 0:\n",
    "        cv2.destroyWindow('Select ROI - Top Left Signal')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f42586e-6379-4544-ac6f-ebc59be333b0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Opens frame at chosen start to draw the ROI of the top right signal\n",
    "ret, frame = video_capture.read()\n",
    "cv2.namedWindow('Select ROI - Top Right Signal')\n",
    "cv2.setMouseCallback('Select ROI - Top Right Signal', select_roi1)\n",
    "frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('Select ROI - Top Right Signal', frame)\n",
    "    cv2.moveWindow('Select ROI - Top Right Signal', opening_x, opening_y)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('q') or not ret:\n",
    "        break\n",
    "\n",
    "    if not selecting_roi and roi_width1 > 0 and roi_height1 > 0:\n",
    "        cv2.destroyWindow('Select ROI - Top Right Signal')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e77db6f-014f-4fa1-a57b-4b2c53a6798a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Opens frame at chosen start to draw the ROI of the bottom signal\n",
    "ret, frame = video_capture.read()\n",
    "cv2.namedWindow('Select ROI - Bottom Signal')\n",
    "cv2.setMouseCallback('Select ROI - Bottom Signal', select_roi2)\n",
    "frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('Select ROI - Bottom Signal', frame)\n",
    "    cv2.moveWindow('Select ROI - Bottom Signal', opening_x, opening_y)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('q') or not ret:\n",
    "        break\n",
    "\n",
    "    if not selecting_roi and roi_width2 > 0 and roi_height2 > 0:\n",
    "        cv2.destroyWindow('Select ROI - Bottom Signal')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3204ebcd-6eda-4b85-be39-b5e44a2555b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Opens frame at chosen start to draw the ROI for YOLO detections\n",
    "ret, frame = video_capture.read()\n",
    "cv2.namedWindow('Select ROI - YOLO Detections')\n",
    "cv2.setMouseCallback('Select ROI - YOLO Detections', select_roi3)\n",
    "frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('Select ROI - YOLO Detections', frame)\n",
    "    cv2.moveWindow('Select ROI - YOLO Detections', opening_x, opening_y)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('q') or not ret:\n",
    "        break\n",
    "\n",
    "    if not selecting_roi and roi_width3 > 0 and roi_height3 > 0:\n",
    "        cv2.destroyWindow('Select ROI - YOLO Detections')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77e00287-8fbb-42d0-bfb1-63f0e2135e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opens frame at chosen start to draw the Line for crossings\n",
    "start_pt1, end_pt1, start_pt2, end_pt2 = -1, -1, -1, -1\n",
    "for i in range (2):\n",
    "    global start_pt1, end_pt1, start_pt2, end_pt2\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        cv2.namedWindow('Select Line')\n",
    "        cv2.setMouseCallback('Select Line', select_line)\n",
    "        frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "        cv2.imshow('Select Line', frame)\n",
    "        cv2.moveWindow('Select Line', opening_x, opening_y)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('q') or not ret:\n",
    "            break\n",
    "\n",
    "        if not drawing and line_x1 > 0 and line_y1 > 0:\n",
    "            cv2.destroyWindow('Select Line')\n",
    "            break\n",
    "    if (i == 0):\n",
    "        start_pt1 = (line_x, line_y)\n",
    "        end_pt1 = (line_x1, line_y1)\n",
    "    if (i == 1 ):\n",
    "        start_pt2 = (line_x, line_y)\n",
    "        end_pt2 = (line_x1, line_y1)\n",
    "        \n",
    "    line_x, line_y, line_x1, line_y1 = -1, -1, -1, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b296cb7-b207-44d1-9670-e7a620afbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOLO detection section/declare model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "#Codes for all detections, assuming relev_codes are veh+peds/bikes and ped_codes are peds and bikes, etc.\n",
    "relev_codes = [0, 1, 2, 3, 5, 7]\n",
    "ped_codes = [0]\n",
    "bike_codes = [1]\n",
    "veh_codes = [2, 3, 5, 7]\n",
    "\n",
    "# box_annotator = sv.BoxAnnotator(\n",
    "#     thickness=1,\n",
    "#     text_thickness=1,\n",
    "#     text_scale=0.5\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab5350a-bc18-4df9-9b8d-2301883a44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #How to get class ids\n",
    "# model.model.names\n",
    "# #Relevant ids for current model:\n",
    "# # 0: 'person',\n",
    "# # 1: 'bicycle',\n",
    "# # 2: 'car',\n",
    "# # 3: 'motorcycle',\n",
    "# # 5: 'bus',\n",
    "# # 7: 'truck',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b71e443c-0da1-431b-b8d2-7a29bb3526a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[[        870      268.69      905.77      309.84     0.28253           0]]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "alldone\n"
     ]
    }
   ],
   "source": [
    "# work on saveing the video\n",
    "# Process the video using the selected ROIs\n",
    "\n",
    "frame_count = 0\n",
    "skip_frames = 1 #Added due to slow processing speed, can be removed if processing sped up, 1 representing every other frame, 2 every third frame, etc.\n",
    "skip_count = 0 #Start of skipped frames, must be less than or equal to skip_frames\n",
    "display = True #Shows annotations on video output\n",
    "start_time = time.time() \n",
    "pre_data = np.empty((0, 14)) #np.array for data as processed\n",
    "\n",
    "video_capture = cv2.VideoCapture(video_dir)\n",
    "video_capture.set(cv2.CAP_PROP_POS_MSEC, frame_delay)\n",
    "while video_capture.isOpened():\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if skip_count == skip_frames:\n",
    "        frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "    \n",
    "        \n",
    "        #YOLOv8 section\n",
    "        roi3 = frame[roi_y3:roi_y3+roi_height3, roi_x3:roi_x3+roi_width3]\n",
    "        # roi3 = cv2.cvtColor(roi3, cv2.COLOR_BGR2RGB)\n",
    "        result = model.predict(roi3, classes = relev_codes, agnostic_nms=False, verbose = False, device = 'cpu')[0]\n",
    "        #detections = result.box.xyxy[0]\n",
    "        detectionsCoardinate = np.array(result.boxes.data)\n",
    "        detectionsCoardinate += (roi_x3,roi_y3,roi_x3,roi_y3,0,0)\n",
    "        \n",
    "        \n",
    "    \n",
    "        #Get YOLO box coordinates\n",
    "#         detections_All = np.column_stack((detectionsCoardinate, detections.class_id))\n",
    "        detections_Peds = np.array(detectionsCoardinate[np.isin(detectionsCoardinate[:, 5], ped_codes)])\n",
    "        detections_Bikes = np.array(detectionsCoardinate[np.isin(detectionsCoardinate[:, 5], bike_codes)])\n",
    "        detections_Veh = np.array(detectionsCoardinate[np.isin(detectionsCoardinate[:, 5], veh_codes)])\n",
    "\n",
    "    \n",
    "        # Check overlap\n",
    "        overlap_veh1 = np.any(check_overlap(detections_Veh, start_pt1, end_pt1))\n",
    "        overlap_veh2 = np.any(check_overlap(detections_Veh, start_pt2, end_pt2))\n",
    "        overlap_ped1 = np.any(check_overlap(detections_Peds, start_pt1, end_pt1))\n",
    "        overlap_ped2 = np.any(check_overlap(detections_Peds, start_pt2, end_pt2))\n",
    "\n",
    "        overlap_veh = False \n",
    "        overlap_ped = False\n",
    "        overlap_bike = False\n",
    "        if (overlap_veh1 == 1 )or (overlap_veh2 == 1):\n",
    "            overlap_veh = True\n",
    "        # if (overlap_bike1 == 1 ) or (overlap_bike2 == 1):\n",
    "        #     overlap_bike == True\n",
    "        if (overlap_ped1 == 1) or (overlap_ped2 == 1):\n",
    "            overlap_ped = True\n",
    "            \n",
    "        \n",
    "        #Gets timestamp of frame in video in miliseconds\n",
    "        timestamp = video_capture.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    \n",
    "        print(testing)\n",
    "        \n",
    "        PedCross = ''\n",
    "        VehCross = 'Vehicle not-crossing'\n",
    "#         BikeCross = ''\n",
    "    \n",
    "        if overlap_ped:\n",
    "            PedCross = 'Person Crossing'\n",
    "        if overlap_veh:\n",
    "            VehCross = 'Vehicle Crossing'\n",
    "        # if overlap_bike == 1 :\n",
    "        #     BikeCross = 'Bike Crossing'\n",
    "    \n",
    "        frame_count += 1\n",
    "    \n",
    "        skip_count = 0\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "#         if display:\n",
    "#         #Displays YOLO boxes\n",
    "# #             frame = box_annotator.annotate(\n",
    "# #                 scene=frame,\n",
    "# #                 detectionsCoardinate=detectionsCoardinate,\n",
    "# #                 labels=labels\n",
    "# #             )\n",
    "            \n",
    "#             # Draw rectangles around the ROIs on the frame\n",
    "#             cv2.rectangle(frame, (roi_x, roi_y), (roi_x+roi_width, roi_y+roi_height), (0, 255, 0), 2)\n",
    "#             cv2.rectangle(frame, (roi_x1, roi_y1), (roi_x1+roi_width1, roi_y1+roi_height1), (0, 255, 0), 2)\n",
    "#             cv2.rectangle(frame, (roi_x2, roi_y2), (roi_x2+roi_width2, roi_y2+roi_height2), (0, 255, 0), 2)\n",
    "#             cv2.line(frame, start_pt, end_pt, (128, 0, 128), 2)\n",
    "#             elapsed_time = time.time() - start_time\n",
    "#             fps = frame_count/elapsed_time\n",
    "#             cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255), 2)\n",
    "#             cv2.putText(frame, f\"TIME: {timestamp:.2f}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "#             cv2.putText(frame, f\"TL:\"+ TLShift, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255), 2)\n",
    "#             cv2.putText(frame, f\"TR:\"+ TRShift, (10, 120), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255), 2)\n",
    "#             cv2.putText(frame, f\"BOT:\"+ BotShift, (10, 150), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255), 2)\n",
    "#             cv2.putText(frame, f\"Ped Cross:\"+ PedCross, (10, 180), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255), 2)\n",
    "#             cv2.putText(frame, f\"Veh Cross:\"+ VehCross, (10, 210), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255), 2)\n",
    "#             cv2.putText(frame, f\"Bike Cross:\"+ BikeCross, (10, 240), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255), 2)\n",
    "\n",
    "        for i in detectionsCoardinate:\n",
    "            display_roi(i)\n",
    "            \n",
    "            if indexModule == 2:\n",
    "                cv2.putText(frame, 'Car ' + str(Matchpersent), (car_x, car_y - 3), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 115), 1)\n",
    "            if indexModule == 0:\n",
    "                cv2.putText(frame, 'Person ' + str(Matchpersent), (car_x, car_y - 3), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 115), 1)\n",
    "                \n",
    "            cv2.rectangle(frame, (car_x, car_y), (car_x2, car_y2), (255, 255, 255), 2)\n",
    "        cv2.rectangle(frame, (roi_x, roi_y), (roi_x+roi_width, roi_y+roi_height), (0, 255, 0), 2)\n",
    "        cv2.rectangle(frame, (roi_x1, roi_y1), (roi_x1+roi_width1, roi_y1+roi_height1), (0, 255, 0), 2)\n",
    "        cv2.rectangle(frame, (roi_x2, roi_y2), (roi_x2+roi_width2, roi_y2+roi_height2), (0, 255, 0), 2)\n",
    "        cv2.line(frame, start_pt1, end_pt1, (128, 0, 128), 2)\n",
    "        cv2.line(frame, start_pt2, end_pt2, (128, 0, 128), 2)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        fps = frame_count/elapsed_time\n",
    "        cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f\"TIME: {timestamp:.2f}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f\"Ped Cross:\"+ PedCross, (10, 180), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f\"Veh Cross:\"+ VehCross, (10, 210), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255), 2)\n",
    "        \n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow('Video', frame)        \n",
    "        resultVid.write(frame)\n",
    "\n",
    "    else:\n",
    "        frame_count += 1\n",
    "        skip_count += 1\n",
    "\n",
    "    #Breaks the video early\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video_capture.release()\n",
    "resultVid.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('alldone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17772edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "m = (end_pt1[1] - start_pt1[1])/(end_pt1[0]-start_pt1[0])\n",
    "b = (start_pt1[1] - m*start_pt1[0])\n",
    "x1 = detections_Veh[:,0]\n",
    "y1 = detections_Veh[:,1]  \n",
    "x2 = detections_Veh[:,2]\n",
    "y2 = detections_Veh[:,3]    \n",
    "overlap  = False \n",
    "results = []\n",
    "i = 0\n",
    "while i < len(detections_Veh):\n",
    "    if m*x2[i]+b < y2[i] and m*x1[i]+b > y2[i]:\n",
    "        overlap = True\n",
    "    elif m*x2[i]+b > y2[i]and m*x1[i]+b < y1[i]:\n",
    "        overlap = True\n",
    "    else:\n",
    "        overlap = False\n",
    "    i+=1\n",
    "    results.append(overlap)\n",
    "    print(overlap)\n",
    "results = np.array(results)\n",
    "print (results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdcb5a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "test = np.array(detectionsCoardinate[np.isin(detectionsCoardinate[:, 5], veh_codes)])\n",
    "print(np.any(check_overlap(detections_Veh, start_pt1, end_pt1)))\n",
    "print(np.any(check_overlap(detections_Veh, start_pt2, end_pt2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3baa6e56-4d1c-4185-8a3c-4bcf8db68c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 6), dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectionsCoardinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "120e25fa-af23-4657-9aa2-6065527f187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building pandas dataframe from date extracted from video feed.\n",
    "STL1 = np.where(np.any(np.abs(np.subtract(reference_color, pre_data[:, [2,3,4]])) > threshold, axis = 1),1,0)\n",
    "STR1 = np.where(np.any(np.abs(np.subtract(reference_color, pre_data[:, [5,6,7]])) > threshold, axis = 1),1,0)\n",
    "SB1 = np.where(np.any(np.abs(np.subtract(reference_color, pre_data[:, [8,9,10]])) > threshold, axis = 1),1,0)\n",
    "\n",
    "df_Data = pd.DataFrame({\n",
    "    'Frame': pre_data[:,0], \n",
    "    'Time': pre_data[:,1], \n",
    "    'PHB Phase Code': np.zeros(len(pre_data)), \n",
    "    'Users Event Code': np.zeros(len(pre_data)),  \n",
    "    'Car Cross': pre_data[:,11], \n",
    "    'Ped Cross': pre_data[:,12],\n",
    "    'Bike Cross': pre_data[:,13]\n",
    "})\n",
    "\n",
    "\n",
    "pre_Check = True\n",
    "yellow = False\n",
    "solid = False\n",
    "flash_Red = False\n",
    "df_Data['Cur Phase'] = 0\n",
    "df_Data['Phase'] = 0\n",
    "\n",
    "#Overlap of all lights\n",
    "\n",
    "i = 0\n",
    "\n",
    "#Gets proper phases, assuming data starts from an off phase\n",
    "while i < len(df_Data):\n",
    "    \n",
    "    if df_Data.loc[i, 'Cur Phase'] == 1 and pre_Check:\n",
    "        j = i\n",
    "        pre_Check = False\n",
    "        yellow = True\n",
    "        df_Data.loc[i, 'Phase'] = 1\n",
    "    elif df_Data.loc[i, 'Cur Phase'] == 1:\n",
    "        if change_Phase:\n",
    "            df_Data.loc[i, 'Phase'] = 2\n",
    "        else:\n",
    "            df_Data.loc[i, 'Phase'] = 1\n",
    "    elif df_Data.loc[i, 'Cur Phase'] == 0:\n",
    "        pre_Check = True\n",
    "        change_Phase = False\n",
    "        flash_Red = False\n",
    "        if yellow:\n",
    "            df_Data.loc[i, 'Phase'] = 1\n",
    "    elif df_Data.loc[i, 'Cur Phase'] == 2 | df_Data.loc[i, 'Cur Phase'] == 3 and not change_Phase and not pre_Check:\n",
    "        i = j - 1\n",
    "        change_Phase = True\n",
    "        yellow = False\n",
    "        solid = True\n",
    "    elif solid:\n",
    "        if df_Data.loc[i, 'Cur Phase'] == 2:\n",
    "            df_Data.loc[i, 'Phase'] = 3          \n",
    "            solid = False\n",
    "        elif df_Data.loc[i, 'Cur Phase'] == 3:\n",
    "            df_Data.loc[i, 'Phase'] = 3\n",
    "    elif df_Data.loc[i, 'Cur Phase'] == 2 and change_Phase:\n",
    "        if flash_Red:\n",
    "            df_Data.loc[i, 'Phase'] = 4\n",
    "        else:\n",
    "            df_Data.loc[i, 'Phase'] = 3\n",
    "    elif df_Data.loc[i, 'Cur Phase'] == 3:\n",
    "        df_Data.loc[i, 'Phase'] = 4\n",
    "        flash_Red = True\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "#Bin up data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38efe034-7c4a-492d-9b97-58aab105415d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a92305f-d6dc-462f-9be4-b615bf84fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check a frame\n",
    "check_frame = False\n",
    "\n",
    "#Time of desired frame to be checked\n",
    "frame_delay = 70303.5666666667\n",
    "\n",
    "#Pulls up frame desired to be checked\n",
    "if check_frame:\n",
    "    video_capture = cv2.VideoCapture(video_dir)\n",
    "    video_capture.set(cv2.CAP_PROP_POS_MSEC, frame_delay)\n",
    "\n",
    "    \n",
    "    # Read the frame at the desired position\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    # Check if the frame was read successfully\n",
    "    if ret:\n",
    "        # Display the frame\n",
    "        frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "        cv2.imshow('Frame', frame)\n",
    "        cv2.waitKey(0)\n",
    "    else:\n",
    "        print(\"Unable to read the frame.\")\n",
    "    \n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f1f35ea-cc28-4874-8f13-756af6577e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Video\n",
    "#When run, true or false dictates if a frame to be checked should be pulled up\n",
    "check_frame = False\n",
    "\n",
    "#Time of desired frame to be checked\n",
    "frame_delay = 84451.0333333333\n",
    "\n",
    "if check_frame:\n",
    "    video_capture = cv2.VideoCapture(video_dir)\n",
    "    video_capture.set(cv2.CAP_PROP_POS_MSEC, frame_delay)\n",
    "    \n",
    "    while video_capture.isOpened():\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "        # Display the frame with the ROI\n",
    "        cv2.imshow('Video', frame)\n",
    "    \n",
    "        #Breaks the video early\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Release the video capture and close all windows\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d67285-c524-47bc-a872-4fc73159f1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a20715-f803-4e9b-8bbd-b0f6100c8eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db1384c-adad-4a8b-aead-7c04ccf73faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
